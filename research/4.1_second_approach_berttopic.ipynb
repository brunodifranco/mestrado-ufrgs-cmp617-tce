{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AnyStr\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"src\")\n",
    "from data_cleaning import DataCleaning\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75280182/topic-modelling-coherence-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 15:31:36 - INFO - Data loaded!\n",
      "2024-04-01 15:31:36 - INFO - Null values cleaned!\n",
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/src/data_cleaning_pandas.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final[\"ANO_LICITACAO\"] = df_final[\"ANO_LICITACAO\"].replace(\n",
      "2024-04-01 15:31:36 - INFO - Data types asserted!\n",
      "2024-04-01 15:31:36 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaning_pipeline = DataCleaning()\n",
    "df = cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"DS_OBJETO\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 15:47:02 - INFO - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "2024-04-01 15:47:04 - INFO - Use pytorch device_name: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22433f7dfaf54e68b271338669755535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=5,\n",
    "    zeroshot_topic_list=[\n",
    "        \"vehicles\",\n",
    "        \"construction\",\n",
    "        \"health/hospital\",\n",
    "        \"education\",\n",
    "        \"food\",\n",
    "    ],\n",
    "    min_topic_size=5,\n",
    "    language=\"brazilian portuguese\",\n",
    "    low_memory=True,\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial[\"clusters\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "6    3026\n",
       "5    1569\n",
       "7     279\n",
       "8      38\n",
       "0      25\n",
       "1      17\n",
       "2      17\n",
       "9      12\n",
       "3       9\n",
       "4       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial[\"clusters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 15:46:10 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-04-01 15:46:10 - INFO - built Dictionary<10240 unique tokens: ['5mx5m', 'aquisição', 'de', 'medindo', 'piramidal']...> from 5000 documents (total 106326 corpus positions)\n",
      "2024-04-01 15:46:10 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<10240 unique tokens: ['5mx5m', 'aquisição', 'de', 'medindo', 'piramidal']...> from 5000 documents (total 106326 corpus positions)\", 'datetime': '2024-04-01T15:46:10.103140', 'gensim': '4.3.2', 'python': '3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]', 'platform': 'Linux-6.5.0-26-generic-x86_64-with-glibc2.35', 'event': 'created'}\n",
      "2024-04-01 15:46:10 - INFO - using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - serializing accumulator to return to master...\n",
      "2024-04-01 15:46:10 - INFO - accumulator serialized\n",
      "2024-04-01 15:46:10 - INFO - 15 accumulators retrieved from output queue\n",
      "2024-04-01 15:46:10 - INFO - accumulated word occurrence stats for 6592 virtual documents\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4897245392389076"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
