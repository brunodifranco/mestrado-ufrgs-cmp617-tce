{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AnyStr\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"src\")\n",
    "from data_cleaning import DataCleaning\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre as métricas de avaliação\n",
    "https://github.com/dice-group/Palmetto/issues/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"zero-shot-classification\",\n",
    "#     model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n",
    "#     framework=\"pt\",\n",
    "#     device=device,\n",
    "#     batch_size=16,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 22:35:44 - INFO - Data loaded!\n",
      "2024-04-05 22:35:45 - INFO - Null values cleaned!\n",
      "2024-04-05 22:35:45 - INFO - Data types asserted!\n",
      "2024-04-05 22:35:45 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "data_cleaning_pipeline = DataCleaning()\n",
    "df = data_cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nlp import preprocess, remove_stop_words, stemmer_pt, lemma_pt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.assign(\n",
    "#     DS_OBJETO_NLP=df[\"DS_OBJETO\"]\n",
    "#     .apply(\n",
    "#         lambda x: nltk.word_tokenize(x.lower(), language=\"portuguese\")\n",
    "#     )  # Tokenize\n",
    "#     .apply(lambda x: [preprocess(word) for word in x])  # Other preprocessing\n",
    "#     .apply(lambda x: list(filter(None, x)))  # Removes items with none\n",
    "#     .apply(remove_stop_words)  # Removes stop words\n",
    "#     .apply(\n",
    "#         lambda x: [word for word in x if \"rs\" not in word]\n",
    "#     )  # Remove tokens containing \"rs\" (which are cities)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(1000)\n",
    "\n",
    "data = Dataset.from_pandas(df)\n",
    "docs = data[\"DS_OBJETO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "# ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "with open(\"/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/src/utils/stop_words.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        stop_words.append(row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words)\n",
    "# topic_model = BERTopic(vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "#                        \"escola, alimenticio, educacao\", \n",
    "#                        \"limpeza, obra, predio\", \n",
    "#                        \"rua, construcao, pavimentacao\", \n",
    "#                        \"saude, medico, familia\",\n",
    "#                        \"servico, transporte, instalacao\",\n",
    "#                        \"veiculos, maquinas, frota\"]\n",
    "\n",
    "# # We fit our model using the zero-shot topics\n",
    "# # and we define a minimum similarity. For each document,\n",
    "# # if the similarity does not exceed that value, it will be used\n",
    "# # for clustering instead.\n",
    "# topic_model = BERTopic(\n",
    "#     embedding_model=\"all-MiniLM-L6-v2\", \n",
    "#     language=\"brazilian portuguese\",\n",
    "#     min_topic_size=15,\n",
    "#     zeroshot_topic_list=zeroshot_topic_list,\n",
    "#     zeroshot_min_similarity=.4,\n",
    "#     representation_model=KeyBERTInspired(),\n",
    "#     vectorizer_model=vectorizer_model\n",
    "\n",
    "# )\n",
    "# topics, _ = topic_model.fit_transform(docs[\"DS_OBJETO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim.corpora as corpora\n",
    "# from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_docs = topic_model._preprocess_text(docs[\"DS_OBJETO\"])\n",
    "# vectorizer = topic_model.vectorizer_model\n",
    "# analyzer = vectorizer.build_analyzer()\n",
    "# tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "# dictionary = corpora.Dictionary(tokens)\n",
    "# corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "# topics = topic_model.get_topics()\n",
    "# topics.pop(-1, None)\n",
    "# topic_words = [\n",
    "# [word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "# ]\n",
    "# topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "#         for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# # Evaluate\n",
    "# coherence_model = CoherenceModel(topics=topic_words, \n",
    "#                             texts=tokens, \n",
    "#                             corpus=corpus,\n",
    "#                             dictionary=dictionary, \n",
    "#                             coherence='c_v')\n",
    "# coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128753/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.5,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoherenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50116</td>\n",
       "      <td>rua, construcao, pavimentacao</td>\n",
       "      <td>[construção, pavimentação, administração, real...</td>\n",
       "      <td>[Contratação de empresa para a execução de obr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32458</td>\n",
       "      <td>servico, transporte, instalacao</td>\n",
       "      <td>[contratação, serviços, administração, serviço...</td>\n",
       "      <td>[CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21647</td>\n",
       "      <td>saude, medico, familia</td>\n",
       "      <td>[medicamentos, médicos, medico, médico, atendi...</td>\n",
       "      <td>[Registro de Preço para a futura e eventual aq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12989</td>\n",
       "      <td>Escola, Educação</td>\n",
       "      <td>[alimentação, alimentacao, alimentícios, alime...</td>\n",
       "      <td>[Eventual e futura aquisição de gêneros alimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8996</td>\n",
       "      <td>veiculos, maquinas, frota</td>\n",
       "      <td>[pneus, veículos, veiculos, aquisição, proteto...</td>\n",
       "      <td>[AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1308</td>\n",
       "      <td>limpeza, obra, predio</td>\n",
       "      <td>[limpeza, limpa, limpador, aquisição, aquisiçõ...</td>\n",
       "      <td>[Aquisição de Material de Limpeza., Aquisição ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1239</td>\n",
       "      <td>eletrica, hidraulica</td>\n",
       "      <td>[hidráulicas, hidraulica, hidráulica, hidrauli...</td>\n",
       "      <td>[AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                             Name  \\\n",
       "0      0  50116    rua, construcao, pavimentacao   \n",
       "1      1  32458  servico, transporte, instalacao   \n",
       "2      2  21647           saude, medico, familia   \n",
       "3      3  12989                 Escola, Educação   \n",
       "4      4   8996        veiculos, maquinas, frota   \n",
       "5      5   1308            limpeza, obra, predio   \n",
       "6      6   1239             eletrica, hidraulica   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [construção, pavimentação, administração, real...   \n",
       "1  [contratação, serviços, administração, serviço...   \n",
       "2  [medicamentos, médicos, medico, médico, atendi...   \n",
       "3  [alimentação, alimentacao, alimentícios, alime...   \n",
       "4  [pneus, veículos, veiculos, aquisição, proteto...   \n",
       "5  [limpeza, limpa, limpador, aquisição, aquisiçõ...   \n",
       "6  [hidráulicas, hidraulica, hidráulica, hidrauli...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa para a execução de obr...  \n",
       "1  [CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...  \n",
       "2  [Registro de Preço para a futura e eventual aq...  \n",
       "3  [Eventual e futura aquisição de gêneros alimen...  \n",
       "4  [AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...  \n",
       "5  [Aquisição de Material de Limpeza., Aquisição ...  \n",
       "6  [AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    low_memory=True,\n",
    "    # zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.7,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4153744865189709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>construction</td>\n",
       "      <td>[empresas, empreitada, revitalização, paviment...</td>\n",
       "      <td>[Contratação de empresa, por regime de empreit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>health/hospital</td>\n",
       "      <td>[medicamentos, médico, referência, consultas, ...</td>\n",
       "      <td>[Constitui objeto da presente licitação o REGI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>education</td>\n",
       "      <td>[educação, educacao, escolares, escolas, escol...</td>\n",
       "      <td>[Contratação de prestação de serviços de Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>food</td>\n",
       "      <td>[alimentação, alimentacao, alimenticios, alime...</td>\n",
       "      <td>[AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>[referência, retroescavadeira, especificações,...</td>\n",
       "      <td>[Contratação de serviços de transporte com cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count             Name  \\\n",
       "0      0    332     construction   \n",
       "1      1    246  health/hospital   \n",
       "2      2    195        education   \n",
       "3      3    120             food   \n",
       "4      4    107         vehicles   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [empresas, empreitada, revitalização, paviment...   \n",
       "1  [medicamentos, médico, referência, consultas, ...   \n",
       "2  [educação, educacao, escolares, escolas, escol...   \n",
       "3  [alimentação, alimentacao, alimenticios, alime...   \n",
       "4  [referência, retroescavadeira, especificações,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa, por regime de empreit...  \n",
       "1  [Constitui objeto da presente licitação o REGI...  \n",
       "2  [Contratação de prestação de serviços de Trans...  \n",
       "3  [AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...  \n",
       "4  [Contratação de serviços de transporte com cam...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75280182/topic-modelling-coherence-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 00:27:15 - INFO - Data loaded!\n",
      "2024-04-05 00:27:15 - INFO - Null values cleaned!\n",
      "2024-04-05 00:27:15 - INFO - Data types asserted!\n",
      "2024-04-05 00:27:15 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaning_pipeline = DataCleaning()\n",
    "df = cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"DS_OBJETO\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=5,\n",
    "    zeroshot_topic_list=[\n",
    "        \"vehicles\",\n",
    "        \"construction\",\n",
    "        \"health\",\n",
    "        \"education\",\n",
    "        \"food\",\n",
    "    ],\n",
    "    min_topic_size=100,\n",
    "    language=\"brazilian portuguese\",\n",
    "    low_memory=True,\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clusters\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "6    77159\n",
       "5    41767\n",
       "7     6000\n",
       "8     2829\n",
       "0      249\n",
       "1      205\n",
       "2      186\n",
       "9      150\n",
       "3      133\n",
       "4       75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clusters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532182199601841"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
