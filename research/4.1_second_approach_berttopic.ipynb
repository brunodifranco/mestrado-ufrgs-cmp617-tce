{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AnyStr\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"src\")\n",
    "from data_cleaning import DataCleaning\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 22:37:33.036885: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-13 22:37:33.037791: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 22:37:33.086062: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 22:37:33.292252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 22:37:33.960601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre as métricas de avaliação\n",
    "https://github.com/dice-group/Palmetto/issues/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# # pipe = pipeline(\n",
    "# #     \"zero-shot-classification\",\n",
    "# #     model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n",
    "# #     framework=\"pt\",\n",
    "# #     device=device,\n",
    "# #     batch_size=16,\n",
    "# # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 22:37:36 - INFO - Data loaded!\n",
      "2024-04-13 22:37:37 - INFO - Null values cleaned!\n",
      "2024-04-13 22:37:37 - INFO - Data types asserted!\n",
      "2024-04-13 22:37:37 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "data_cleaning_pipeline = DataCleaning()\n",
    "df = data_cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df)\n",
    "docs = data[\"DS_OBJETO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "with open(\"/home/brunodifranco/mestrado/mestrado-ufrgs-cmp617-tce/src/utils/stop_words.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        stop_words.append(row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unidecode import unidecode\n",
    "def preprocess(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies NLP preprocess in string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: str\n",
    "        Raw string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x: str\n",
    "        String with NLP preprocess applied.\n",
    "    \"\"\"\n",
    "\n",
    "    special_chars = \"¨'!#$%&()*+,./:;<=>?@[\\]^_`{|}~\"\n",
    "    new_x = x.replace('\"', \" \")\n",
    "    for c in special_chars:\n",
    "        new_x = new_x.replace(c, \" \")  # Removes special characters\n",
    "    new_x = re.sub(r\"[^\\w\\s]\", \" \", new_x)  # Removes punctuation\n",
    "    new_x = re.sub(r'\\d+', '', new_x) # Remove numbers\n",
    "    new_x = re.sub(\"http\\S+\", \" \", new_x)  # Removes links\n",
    "    new_x = re.sub(\"@\\w+\", \" \", new_x)  # Removes @\n",
    "    new_x = re.sub(\"#\\S+\", \" \", new_x)  # Removes hashtags\n",
    "    new_x = re.sub(\"[0-9]+\", \" \", new_x)  # Removes numbers\n",
    "    new_x = unidecode(new_x)  # Removes accents\n",
    "    new_x = re.sub(\"\\s+\", \" \", new_x)  # Removes spaces\n",
    "\n",
    "    new_x = \" \".join([word for word in new_x.split() if len(word) > 2])\n",
    "\n",
    "    new_x = new_x.strip()\n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VER PQ O COUNT VEC NAO ESTA FAZENDO CORRETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(preprocessor=preprocess, strip_accents=\"unicode\", stop_words=stop_words)\n",
    "# topic_model = BERTopic(vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=\"auto\",\n",
    "    embedding_model=\"paraphrase-multilingual-MiniLM-L12-v2\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=500,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunodifranco/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: [('Administracao', 0.5369319),\n",
       "  ('EQUIPAMENTOS', 0.53418946),\n",
       "  ('FAMILIA', 0.53296554),\n",
       "  ('FAMILIAR', 0.53011256),\n",
       "  ('ACESSORIOS', 0.5279908),\n",
       "  ('ESPECIALIZADA', 0.52254117),\n",
       "  ('empreitada', 0.52153933),\n",
       "  ('PRECOS', 0.50913227),\n",
       "  ('MATERIAIS', 0.5024395),\n",
       "  ('CREDENCIAMENTO', 0.50199306)],\n",
       " 0: [('EMPRESA', 0.5568217),\n",
       "  ('ADMINISTRATIVO', 0.5531671),\n",
       "  ('construcao', 0.54614264),\n",
       "  ('CONTRATACAO', 0.54435706),\n",
       "  ('EQUIPAMENTOS', 0.54170734),\n",
       "  ('Contratacao', 0.5384912),\n",
       "  ('empreitada', 0.51570594),\n",
       "  ('Pavimentacao', 0.51187545),\n",
       "  ('MATERIAL', 0.5111704),\n",
       "  ('CONSTRUCAO', 0.5049845)],\n",
       " 1: [('ALIMENTICIOS', 0.7480488),\n",
       "  ('alimenticios', 0.70567113),\n",
       "  ('ALIMENTOS', 0.70231503),\n",
       "  ('Alimentos', 0.6913591),\n",
       "  ('Alimenticios', 0.6878598),\n",
       "  ('alimentos', 0.67116845),\n",
       "  ('Alimentacao', 0.67110467),\n",
       "  ('ALIMENTACAO', 0.6273705),\n",
       "  ('produtos', 0.54938906),\n",
       "  ('Fornecimento', 0.5378494)],\n",
       " 2: [('ESCOLAS', 0.7467952),\n",
       "  ('Escolas', 0.7289226),\n",
       "  ('escolas', 0.7238859),\n",
       "  ('escolares', 0.72167873),\n",
       "  ('ESCOLARES', 0.7146305),\n",
       "  ('escolar', 0.7138077),\n",
       "  ('ESCOLAR', 0.71316975),\n",
       "  ('Escola', 0.70798886),\n",
       "  ('Escolar', 0.68540055),\n",
       "  ('escola', 0.6791781)],\n",
       " 3: [('automotor', 0.64052963),\n",
       "  ('motorista', 0.640267),\n",
       "  ('Van', 0.6369047),\n",
       "  ('rodas', 0.6110951),\n",
       "  ('transporte', 0.55482495),\n",
       "  ('Ford', 0.5463865),\n",
       "  ('equipamento', 0.53834397),\n",
       "  ('maquina', 0.5343237),\n",
       "  ('Mercedes', 0.5154103),\n",
       "  ('Cargo', 0.5119951)],\n",
       " 4: [('Festival', 0.57340777),\n",
       "  ('FESTIVAL', 0.56329155),\n",
       "  ('decoracao', 0.5398819),\n",
       "  ('Festejando', 0.5244249),\n",
       "  ('tendas', 0.5107086),\n",
       "  ('Festa', 0.5042869),\n",
       "  ('celebracao', 0.503222),\n",
       "  ('Natal', 0.4881658),\n",
       "  ('Projeto', 0.4489829),\n",
       "  ('Municipal', 0.44649798)],\n",
       " 5: [('Gasolina', 0.63149154),\n",
       "  ('gasolina', 0.6216524),\n",
       "  ('diesel', 0.61867666),\n",
       "  ('Combustivel', 0.6168058),\n",
       "  ('Diesel', 0.6166667),\n",
       "  ('combustivel', 0.61133003),\n",
       "  ('petroleo', 0.5721561),\n",
       "  ('CARGAS', 0.56931925),\n",
       "  ('GAS', 0.5347129),\n",
       "  ('Gas', 0.4950517)],\n",
       " 6: [('Agricultura', 0.6115153),\n",
       "  ('AGRICULTURA', 0.6109581),\n",
       "  ('agricola', 0.60372233),\n",
       "  ('agricolas', 0.5941508),\n",
       "  ('MINISTERIO', 0.55114245),\n",
       "  ('FARMACIA', 0.5331528),\n",
       "  ('SECRETARIA', 0.53245425),\n",
       "  ('Ministerio', 0.5152271),\n",
       "  ('Secretaria', 0.5070088),\n",
       "  ('MUNICIPAL', 0.48595956)],\n",
       " 7: [('clinicas', 0.6597984),\n",
       "  ('Clinicas', 0.65755916),\n",
       "  ('clinica', 0.6422515),\n",
       "  ('Clinica', 0.6317396),\n",
       "  ('medicos', 0.6233208),\n",
       "  ('clinico', 0.61223114),\n",
       "  ('Clinico', 0.61159575),\n",
       "  ('consultas', 0.5786461),\n",
       "  ('medico', 0.57030606),\n",
       "  ('Medico', 0.54803085)],\n",
       " 8: [('AGRICULTURA', 0.63985646),\n",
       "  ('Agricultura', 0.62237173),\n",
       "  ('agricultura', 0.59548813),\n",
       "  ('ALIMENTOS', 0.58806425),\n",
       "  ('alimenticios', 0.5832852),\n",
       "  ('ALIMENTICIOS', 0.5723632),\n",
       "  ('alimentos', 0.5535717),\n",
       "  ('Alimenticios', 0.53753257),\n",
       "  ('Alimentacao', 0.4925616),\n",
       "  ('Rural', 0.49149722)],\n",
       " 9: [('transporte', 0.5812874),\n",
       "  ('TRANSPORTE', 0.57089776),\n",
       "  ('EMPRESAS', 0.5591501),\n",
       "  ('Transporte', 0.5572909),\n",
       "  ('Empresa', 0.539171),\n",
       "  ('EMPRESA', 0.53516996),\n",
       "  ('Contratacao', 0.5319817),\n",
       "  ('empresas', 0.52823997),\n",
       "  ('EDUCACAO', 0.5268674),\n",
       "  ('escolas', 0.52602285)],\n",
       " 10: [('agua', 0.63818383),\n",
       "  ('aguas', 0.62485504),\n",
       "  ('hidrojateamento', 0.62367165),\n",
       "  ('hidraulicos', 0.5995748),\n",
       "  ('hidraulico', 0.49315584),\n",
       "  ('hidrometros', 0.4758739),\n",
       "  ('Abastecimento', 0.4546943),\n",
       "  ('abastecimento', 0.39549285),\n",
       "  ('higienizacao', 0.38681704),\n",
       "  ('purificadores', 0.3675963)],\n",
       " 11: [('brinquedos', 0.8821471),\n",
       "  ('Brinquedos', 0.70291495),\n",
       "  ('jogos', 0.5910425),\n",
       "  ('Jogos', 0.57391995),\n",
       "  ('PLAYGROUNDS', 0.525811),\n",
       "  ('playground', 0.5103681),\n",
       "  ('Playground', 0.50620145),\n",
       "  ('infantil', 0.50422),\n",
       "  ('infantis', 0.49191085),\n",
       "  ('PLAYGROUND', 0.4861906)],\n",
       " 12: [('Higiene', 0.8267124),\n",
       "  ('higiene', 0.82321393),\n",
       "  ('higienico', 0.72525996),\n",
       "  ('higienizacao', 0.715291),\n",
       "  ('limpeza', 0.68942523),\n",
       "  ('lavar', 0.6615826),\n",
       "  ('limpador', 0.6272881),\n",
       "  ('lavadora', 0.59035367),\n",
       "  ('limpa', 0.57070774),\n",
       "  ('sabonete', 0.5658159)],\n",
       " 13: [('Material', 0.65149295),\n",
       "  ('Materiais', 0.61845946),\n",
       "  ('especificacoesconstantes', 0.6140232),\n",
       "  ('Equipamentos', 0.5866697),\n",
       "  ('ferramentas', 0.57113194),\n",
       "  ('manual', 0.52652323),\n",
       "  ('plastico', 0.5209083),\n",
       "  ('plasticas', 0.5204177),\n",
       "  ('plastica', 0.518054),\n",
       "  ('fita', 0.50382185)],\n",
       " 14: [('HUMANO', 0.6058734),\n",
       "  ('FAMILIA', 0.53209996),\n",
       "  ('USO', 0.4987152),\n",
       "  ('EXCEPCIONAIS', 0.46422818),\n",
       "  ('GENERICOS', 0.4279989),\n",
       "  ('ESPECIAIS', 0.40640688),\n",
       "  ('INFANCIA', 0.4050673),\n",
       "  ('PERSONALIZADO', 0.40449563),\n",
       "  ('DESENVOLVIMENTO', 0.39630133),\n",
       "  ('MATERIAIS', 0.38383663)],\n",
       " 15: [('Internet', 0.68757725),\n",
       "  ('internet', 0.68633014),\n",
       "  ('INTERNET', 0.6826103),\n",
       "  ('telecomunicacoes', 0.5485976),\n",
       "  ('WEB', 0.49191892),\n",
       "  ('digital', 0.48969373),\n",
       "  ('DIGITAL', 0.4884728),\n",
       "  ('intranet', 0.48065856),\n",
       "  ('EMPRESA', 0.46006617),\n",
       "  ('INFORMATICA', 0.45153105)],\n",
       " 16: [('pneus', 0.9018444),\n",
       "  ('pneu', 0.8884722),\n",
       "  ('pneumaticos', 0.46870685),\n",
       "  ('Chevrolet', 0.44548157),\n",
       "  ('veiculos', 0.39814845),\n",
       "  ('maquinas', 0.38956118),\n",
       "  ('Maquinas', 0.38163215),\n",
       "  ('prestacoes', 0.3632956),\n",
       "  ('rodoviarias', 0.3622725),\n",
       "  ('montagem', 0.35793006)],\n",
       " 17: [('lampadas', 0.7465409),\n",
       "  ('iluminacao', 0.6774706),\n",
       "  ('lampada', 0.6765243),\n",
       "  ('luz', 0.6579272),\n",
       "  ('LED', 0.62524796),\n",
       "  ('refletores', 0.6215481),\n",
       "  ('luminarias', 0.53114545),\n",
       "  ('Lampadas', 0.5068598),\n",
       "  ('tecnologia', 0.43356168),\n",
       "  ('luminaria', 0.42500415)],\n",
       " 18: [('Registro', 0.56470823),\n",
       "  ('REGISTRO', 0.51652455),\n",
       "  ('Secretarias', 0.45159614),\n",
       "  ('Secretaria', 0.4229076),\n",
       "  ('Administracao', 0.3840993),\n",
       "  ('assinatura', 0.35919687),\n",
       "  ('data', 0.3378337),\n",
       "  ('contados', 0.32721055),\n",
       "  ('Contratacao', 0.32473978),\n",
       "  ('Obras', 0.31829548)],\n",
       " 19: [('veterinaria', 0.7161806),\n",
       "  ('veterinarios', 0.7128631),\n",
       "  ('veterinario', 0.70954216),\n",
       "  ('Veterinaria', 0.7022046),\n",
       "  ('Veterinario', 0.6864873),\n",
       "  ('caninas', 0.56328905),\n",
       "  ('caninos', 0.54372406),\n",
       "  ('canina', 0.51924896),\n",
       "  ('animal', 0.47772178),\n",
       "  ('Animal', 0.4773145)],\n",
       " 20: [('Videomonitoramento', 0.8185038),\n",
       "  ('videomonitoramento', 0.814607),\n",
       "  ('VIDEOMONITORAMENTO', 0.78592885),\n",
       "  ('cameras', 0.77463925),\n",
       "  ('Webcam', 0.7390077),\n",
       "  ('camera', 0.70279545),\n",
       "  ('CAMERA', 0.68549705),\n",
       "  ('videoconferencia', 0.68049103),\n",
       "  ('FILMAGEM', 0.60795045),\n",
       "  ('monitoramento', 0.60403407)],\n",
       " 21: [('Contratacao', 0.82906014),\n",
       "  ('Servico', 0.752962),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484),\n",
       "  ('', 0.52349484)],\n",
       " 22: [('MATERIAL', 0.61085373),\n",
       "  ('RECICLADOS', 0.60400975),\n",
       "  ('COMPLEMENTACAO', 0.5956543),\n",
       "  ('REQ', 0.5872698),\n",
       "  ('RECARREGAVEL', 0.5866531),\n",
       "  ('RENOVAVEIS', 0.5844307),\n",
       "  ('EQUIPAMENTOS', 0.5823666),\n",
       "  ('MATERIAIS', 0.5794453),\n",
       "  ('REFRIGERADOR', 0.57252836),\n",
       "  ('COMPRIMENTO', 0.5717596)],\n",
       " 23: [('HOSPITALTRAMANDAI', 0.74515414),\n",
       "  ('HOSPITAL', 0.68170404),\n",
       "  ('Hospital', 0.6791726),\n",
       "  ('HOSPITALAR', 0.6705488),\n",
       "  ('OHOSPITAL', 0.6306767),\n",
       "  ('MEDICO', 0.52109087),\n",
       "  ('MEDICAMENTO', 0.5192574),\n",
       "  ('MEDICAMENTOS', 0.4954863),\n",
       "  ('MUNICIPALGETULIO', 0.46942154),\n",
       "  ('MEDICA', 0.45028836)],\n",
       " 24: [('ZERO', 0.59009403),\n",
       "  ('Zero', 0.5801431),\n",
       "  ('TRANSPORTE', 0.5279115),\n",
       "  ('MINIMO', 0.5008794),\n",
       "  ('MINIMA', 0.4942609),\n",
       "  ('MINIMAS', 0.4700088),\n",
       "  ('MINIVAN', 0.45719105),\n",
       "  ('AQUISICAO', 0.45556808),\n",
       "  ('MUNICIPIO', 0.43452662),\n",
       "  ('ASSISTENCIA', 0.42727876)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32573811700719185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38325406997071965"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('construção', 0.5681251),\n",
       "  ('elaboração', 0.4624865),\n",
       "  ('educação', 0.459426),\n",
       "  ('sinalização', 0.45752037),\n",
       "  ('realização', 0.45623952),\n",
       "  ('locação', 0.43234518),\n",
       "  ('contratação', 0.42779756),\n",
       "  ('assistência', 0.4154815),\n",
       "  ('ampliação', 0.4142847),\n",
       "  ('alimentícios', 0.4107704)],\n",
       " 1: [('medicamentos', 0.57149994),\n",
       "  ('medicamento', 0.5577508),\n",
       "  ('hospitalares', 0.49077398),\n",
       "  ('farmacológico', 0.4874243),\n",
       "  ('médico', 0.4246473),\n",
       "  ('pacientes', 0.41410685),\n",
       "  ('médicos', 0.40300336),\n",
       "  ('distribuição', 0.38603836),\n",
       "  ('farmacêutica', 0.37632835),\n",
       "  ('hospital', 0.3673182)],\n",
       " 2: [('maquinas', 0.6246067),\n",
       "  ('máquinas', 0.6246066),\n",
       "  ('maquina', 0.5850227),\n",
       "  ('máquina', 0.58502257),\n",
       "  ('equinos', 0.5608816),\n",
       "  ('maquinários', 0.55405045),\n",
       "  ('maquinário', 0.5539815),\n",
       "  ('serviço', 0.49048704),\n",
       "  ('serviços', 0.47412324),\n",
       "  ('operacional', 0.42325744)],\n",
       " 3: [('transportes', 0.49012938),\n",
       "  ('transporte', 0.47378653),\n",
       "  ('escola', 0.39245474),\n",
       "  ('escolar', 0.37045515),\n",
       "  ('educação', 0.3680548),\n",
       "  ('escolas', 0.35372102),\n",
       "  ('empresas', 0.33104312),\n",
       "  ('disposição', 0.30525744),\n",
       "  ('contratação', 0.2932828),\n",
       "  ('destinação', 0.28489304)],\n",
       " 4: [('odontológicas', 0.6819987),\n",
       "  ('odontológico', 0.66228294),\n",
       "  ('odontologico', 0.66228294),\n",
       "  ('odontológica', 0.6468105),\n",
       "  ('odontologicos', 0.6441914),\n",
       "  ('odontológicos', 0.64419127),\n",
       "  ('odontologia', 0.5613242),\n",
       "  ('dental', 0.48272762),\n",
       "  ('dentarias', 0.39964533),\n",
       "  ('dentárias', 0.39964533)],\n",
       " 5: [('gas', 0.49727488),\n",
       "  ('gás', 0.49727476),\n",
       "  ('gases', 0.4889426),\n",
       "  ('cargas', 0.4680662),\n",
       "  ('gasoso', 0.38848132),\n",
       "  ('petroleo', 0.37785214),\n",
       "  ('petróleo', 0.37785214),\n",
       "  ('mineral', 0.37783244),\n",
       "  ('contratação', 0.3575009),\n",
       "  ('liquefeito', 0.33512443)],\n",
       " 6: [('família', 0.5773749),\n",
       "  ('medicamentos', 0.43382013),\n",
       "  ('panificacao', 0.28914773),\n",
       "  ('alimentacao', 0.21875095),\n",
       "  ('produtos', 0.200993),\n",
       "  ('genericos', 0.1734989),\n",
       "  ('0884', 0.16897243),\n",
       "  ('0880', 0.16705778),\n",
       "  ('0886', 0.16573735),\n",
       "  ('0888', 0.16463363)],\n",
       " 7: [('lubrificantes', 0.68741035),\n",
       "  ('lubrificação', 0.6706677),\n",
       "  ('lubrificacao', 0.6706677),\n",
       "  ('lubrificante', 0.63985145),\n",
       "  ('oleos', 0.41745222),\n",
       "  ('óleos', 0.41745222),\n",
       "  ('oleo', 0.41524166),\n",
       "  ('óleo', 0.41524166),\n",
       "  ('fluidos', 0.3234224),\n",
       "  ('fluídos', 0.32342237)],\n",
       " 8: [('veterinárias', 0.56060463),\n",
       "  ('veterinários', 0.5333289),\n",
       "  ('veterinarios', 0.5333289),\n",
       "  ('veterinária', 0.52192914),\n",
       "  ('veterinaria', 0.52192914),\n",
       "  ('veterinário', 0.48142207),\n",
       "  ('veterinario', 0.48142207),\n",
       "  ('esterilização', 0.3992674),\n",
       "  ('serviços', 0.31938612),\n",
       "  ('serviço', 0.31422174)],\n",
       " 9: [('covid19', 0.6099849),\n",
       "  ('covid', 0.58373827),\n",
       "  ('coronavirus', 0.48441258),\n",
       "  ('coronavírus', 0.48441258),\n",
       "  ('antígeno', 0.37416548),\n",
       "  ('antigeno', 0.37416548),\n",
       "  ('antígenos', 0.36937395),\n",
       "  ('influenza', 0.36300573),\n",
       "  ('testes', 0.345739),\n",
       "  ('vacinação', 0.33982903)],\n",
       " 10: [('uniformes', 0.74527913),\n",
       "  ('uniforme', 0.6944113),\n",
       "  ('aquisição', 0.5228046),\n",
       "  ('departamento', 0.5044154),\n",
       "  ('proteção', 0.4779388),\n",
       "  ('profissionais', 0.47057778),\n",
       "  ('condições', 0.4598155),\n",
       "  ('viação', 0.4422249),\n",
       "  ('contratação', 0.43052405),\n",
       "  ('quisição', 0.41842234)],\n",
       " 11: [('combustíveis', 0.57698774),\n",
       "  ('combustiveis', 0.5769876),\n",
       "  ('combustível', 0.54853356),\n",
       "  ('combustivel', 0.54853356),\n",
       "  ('petróleo', 0.33047712),\n",
       "  ('veículos', 0.32422557),\n",
       "  ('veiculos', 0.32422557),\n",
       "  ('maquinas', 0.314163),\n",
       "  ('máquinas', 0.31416297),\n",
       "  ('veículo', 0.31168604)],\n",
       " 12: [('serviço', 0.65635073),\n",
       "  ('servico', 0.6563507),\n",
       "  ('serviços', 0.62633044),\n",
       "  ('contratação', 0.6194852),\n",
       "  ('recepção', 0.46323994),\n",
       "  ('detalhamento', 0.42137787),\n",
       "  ('desratização', 0.32358006),\n",
       "  ('básico', 0.31826177),\n",
       "  ('contratar', 0.29592687),\n",
       "  ('sucção', 0.27680248)],\n",
       " 13: [('genético', 0.43170244),\n",
       "  ('gêneros', 0.38918376),\n",
       "  ('genêros', 0.38918376),\n",
       "  ('alimenticio', 0.35861802),\n",
       "  ('gênero', 0.3566283),\n",
       "  ('genero', 0.3566283),\n",
       "  ('alimentícios', 0.3524846),\n",
       "  ('alimenticios', 0.3524846),\n",
       "  ('pregão', 0.34780058),\n",
       "  ('alimentação', 0.32296997)],\n",
       " 14: [('financiamento', 0.49127412),\n",
       "  ('financeira', 0.48608592),\n",
       "  ('financeiras', 0.4759139),\n",
       "  ('público', 0.40966973),\n",
       "  ('créditos', 0.34867963),\n",
       "  ('estabelecimentos', 0.34645388),\n",
       "  ('pública', 0.34535557),\n",
       "  ('processamento', 0.32964182),\n",
       "  ('operação', 0.32835746),\n",
       "  ('crédito', 0.32084066)],\n",
       " 15: [('basálticas', 0.65742326),\n",
       "  ('basáltica', 0.64509547),\n",
       "  ('basalto', 0.6449064),\n",
       "  ('basálticos', 0.62323946),\n",
       "  ('pavimentação', 0.3538844),\n",
       "  ('pavimentacao', 0.3538844),\n",
       "  ('pluvial', 0.34927636),\n",
       "  ('sinalização', 0.31837267),\n",
       "  ('contratação', 0.30512154),\n",
       "  ('totalizando', 0.29086575)],\n",
       " 16: [('combustivel', 0.51323694),\n",
       "  ('combustível', 0.51323694),\n",
       "  ('combustiveis', 0.49302167),\n",
       "  ('combustíveis', 0.49302167),\n",
       "  ('diesel', 0.44839713),\n",
       "  ('gasolina', 0.36586624),\n",
       "  ('gás', 0.32888728),\n",
       "  ('comum', 0.23871306),\n",
       "  ('óleo', 0.23655957),\n",
       "  ('oléo', 0.23655957)],\n",
       " 17: [('hospitalares', 0.50538427),\n",
       "  ('hospital', 0.45424542),\n",
       "  ('hospitaltramandaí', 0.44394934),\n",
       "  ('sapucaia', 0.39949772),\n",
       "  ('tramandaí', 0.37575707),\n",
       "  ('tramandai', 0.37575707),\n",
       "  ('consignação', 0.3609044),\n",
       "  ('manutenção', 0.35248423),\n",
       "  ('medicamento', 0.3508247),\n",
       "  ('hospitalar', 0.3479784)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_red = topic_model.reduce_topics(docs, nr_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: [('administração', 0.5128263),\n",
       "  ('construção', 0.48023286),\n",
       "  ('elaboração', 0.47881675),\n",
       "  ('sinalização', 0.47879952),\n",
       "  ('educação', 0.47509193),\n",
       "  ('pavimentação', 0.46780133),\n",
       "  ('contratação', 0.4645041),\n",
       "  ('realização', 0.46154442),\n",
       "  ('assistência', 0.43208027),\n",
       "  ('público', 0.42825383)],\n",
       " 0: [('educação', 0.49767995),\n",
       "  ('construção', 0.4613402),\n",
       "  ('assistência', 0.45131466),\n",
       "  ('referência', 0.42996985),\n",
       "  ('alimentícios', 0.4158863),\n",
       "  ('contratação', 0.4132297),\n",
       "  ('pavimentação', 0.41275293),\n",
       "  ('escola', 0.3991003),\n",
       "  ('transporte', 0.39902392),\n",
       "  ('administração', 0.38902014)],\n",
       " 1: [('gráfico', 0.76230395),\n",
       "  ('grafico', 0.76230395),\n",
       "  ('rp', 0.23458505),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533)],\n",
       " 2: [('medicamentos', 0.99999994),\n",
       "  ('medicamento', 0.9603776),\n",
       "  ('médicos', 0.56999767),\n",
       "  ('doces', 0.40482494),\n",
       "  ('complexidade', 0.29081422),\n",
       "  ('humanos', 0.19442846),\n",
       "  ('alta', 0.18158409),\n",
       "  ('', 0.17246795),\n",
       "  ('', 0.17246795),\n",
       "  ('', 0.17246795)],\n",
       " 3: [('trator', 0.4084736),\n",
       "  ('aquisição', 0.2281385),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727)]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_red.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topics_red._preprocess_text(docs)\n",
    "vectorizer = topics_red.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topics_red.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topics_red.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topics_red.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3720869663260227"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4260404204330265"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nlp import preprocess, remove_stop_words, stemmer_pt, lemma_pt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.assign(\n",
    "#     DS_OBJETO_NLP=df[\"DS_OBJETO\"]\n",
    "#     .apply(\n",
    "#         lambda x: nltk.word_tokenize(x.lower(), language=\"portuguese\")\n",
    "#     )  # Tokenize\n",
    "#     .apply(lambda x: [preprocess(word) for word in x])  # Other preprocessing\n",
    "#     .apply(lambda x: list(filter(None, x)))  # Removes items with none\n",
    "#     .apply(remove_stop_words)  # Removes stop words\n",
    "#     .apply(\n",
    "#         lambda x: [word for word in x if \"rs\" not in word]\n",
    "#     )  # Remove tokens containing \"rs\" (which are cities)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(1000)\n",
    "\n",
    "data = Dataset.from_pandas(df)\n",
    "docs = data[\"DS_OBJETO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "# ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words)\n",
    "# topic_model = BERTopic(vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "#                        \"escola, alimenticio, educacao\", \n",
    "#                        \"limpeza, obra, predio\", \n",
    "#                        \"rua, construcao, pavimentacao\", \n",
    "#                        \"saude, medico, familia\",\n",
    "#                        \"servico, transporte, instalacao\",\n",
    "#                        \"veiculos, maquinas, frota\"]\n",
    "\n",
    "# # We fit our model using the zero-shot topics\n",
    "# # and we define a minimum similarity. For each document,\n",
    "# # if the similarity does not exceed that value, it will be used\n",
    "# # for clustering instead.\n",
    "# topic_model = BERTopic(\n",
    "#     embedding_model=\"all-MiniLM-L6-v2\", \n",
    "#     language=\"brazilian portuguese\",\n",
    "#     min_topic_size=15,\n",
    "#     zeroshot_topic_list=zeroshot_topic_list,\n",
    "#     zeroshot_min_similarity=.4,\n",
    "#     representation_model=KeyBERTInspired(),\n",
    "#     vectorizer_model=vectorizer_model\n",
    "\n",
    "# )\n",
    "# topics, _ = topic_model.fit_transform(docs[\"DS_OBJETO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_docs = topic_model._preprocess_text(docs[\"DS_OBJETO\"])\n",
    "# vectorizer = topic_model.vectorizer_model\n",
    "# analyzer = vectorizer.build_analyzer()\n",
    "# tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "# dictionary = corpora.Dictionary(tokens)\n",
    "# corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "# topics = topic_model.get_topics()\n",
    "# topics.pop(-1, None)\n",
    "# topic_words = [\n",
    "# [word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "# ]\n",
    "# topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "#         for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# # Evaluate\n",
    "# coherence_model = CoherenceModel(topics=topic_words, \n",
    "#                             texts=tokens, \n",
    "#                             corpus=corpus,\n",
    "#                             dictionary=dictionary, \n",
    "#                             coherence='c_v')\n",
    "# coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128753/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.5,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoherenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50116</td>\n",
       "      <td>rua, construcao, pavimentacao</td>\n",
       "      <td>[construção, pavimentação, administração, real...</td>\n",
       "      <td>[Contratação de empresa para a execução de obr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32458</td>\n",
       "      <td>servico, transporte, instalacao</td>\n",
       "      <td>[contratação, serviços, administração, serviço...</td>\n",
       "      <td>[CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21647</td>\n",
       "      <td>saude, medico, familia</td>\n",
       "      <td>[medicamentos, médicos, medico, médico, atendi...</td>\n",
       "      <td>[Registro de Preço para a futura e eventual aq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12989</td>\n",
       "      <td>Escola, Educação</td>\n",
       "      <td>[alimentação, alimentacao, alimentícios, alime...</td>\n",
       "      <td>[Eventual e futura aquisição de gêneros alimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8996</td>\n",
       "      <td>veiculos, maquinas, frota</td>\n",
       "      <td>[pneus, veículos, veiculos, aquisição, proteto...</td>\n",
       "      <td>[AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1308</td>\n",
       "      <td>limpeza, obra, predio</td>\n",
       "      <td>[limpeza, limpa, limpador, aquisição, aquisiçõ...</td>\n",
       "      <td>[Aquisição de Material de Limpeza., Aquisição ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1239</td>\n",
       "      <td>eletrica, hidraulica</td>\n",
       "      <td>[hidráulicas, hidraulica, hidráulica, hidrauli...</td>\n",
       "      <td>[AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                             Name  \\\n",
       "0      0  50116    rua, construcao, pavimentacao   \n",
       "1      1  32458  servico, transporte, instalacao   \n",
       "2      2  21647           saude, medico, familia   \n",
       "3      3  12989                 Escola, Educação   \n",
       "4      4   8996        veiculos, maquinas, frota   \n",
       "5      5   1308            limpeza, obra, predio   \n",
       "6      6   1239             eletrica, hidraulica   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [construção, pavimentação, administração, real...   \n",
       "1  [contratação, serviços, administração, serviço...   \n",
       "2  [medicamentos, médicos, medico, médico, atendi...   \n",
       "3  [alimentação, alimentacao, alimentícios, alime...   \n",
       "4  [pneus, veículos, veiculos, aquisição, proteto...   \n",
       "5  [limpeza, limpa, limpador, aquisição, aquisiçõ...   \n",
       "6  [hidráulicas, hidraulica, hidráulica, hidrauli...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa para a execução de obr...  \n",
       "1  [CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...  \n",
       "2  [Registro de Preço para a futura e eventual aq...  \n",
       "3  [Eventual e futura aquisição de gêneros alimen...  \n",
       "4  [AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...  \n",
       "5  [Aquisição de Material de Limpeza., Aquisição ...  \n",
       "6  [AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    low_memory=True,\n",
    "    # zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.7,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4153744865189709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>construction</td>\n",
       "      <td>[empresas, empreitada, revitalização, paviment...</td>\n",
       "      <td>[Contratação de empresa, por regime de empreit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>health/hospital</td>\n",
       "      <td>[medicamentos, médico, referência, consultas, ...</td>\n",
       "      <td>[Constitui objeto da presente licitação o REGI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>education</td>\n",
       "      <td>[educação, educacao, escolares, escolas, escol...</td>\n",
       "      <td>[Contratação de prestação de serviços de Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>food</td>\n",
       "      <td>[alimentação, alimentacao, alimenticios, alime...</td>\n",
       "      <td>[AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>[referência, retroescavadeira, especificações,...</td>\n",
       "      <td>[Contratação de serviços de transporte com cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count             Name  \\\n",
       "0      0    332     construction   \n",
       "1      1    246  health/hospital   \n",
       "2      2    195        education   \n",
       "3      3    120             food   \n",
       "4      4    107         vehicles   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [empresas, empreitada, revitalização, paviment...   \n",
       "1  [medicamentos, médico, referência, consultas, ...   \n",
       "2  [educação, educacao, escolares, escolas, escol...   \n",
       "3  [alimentação, alimentacao, alimenticios, alime...   \n",
       "4  [referência, retroescavadeira, especificações,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa, por regime de empreit...  \n",
       "1  [Constitui objeto da presente licitação o REGI...  \n",
       "2  [Contratação de prestação de serviços de Trans...  \n",
       "3  [AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...  \n",
       "4  [Contratação de serviços de transporte com cam...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75280182/topic-modelling-coherence-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 00:27:15 - INFO - Data loaded!\n",
      "2024-04-05 00:27:15 - INFO - Null values cleaned!\n",
      "2024-04-05 00:27:15 - INFO - Data types asserted!\n",
      "2024-04-05 00:27:15 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaning_pipeline = DataCleaning()\n",
    "df = cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"DS_OBJETO\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=5,\n",
    "    zeroshot_topic_list=[\n",
    "        \"vehicles\",\n",
    "        \"construction\",\n",
    "        \"health\",\n",
    "        \"education\",\n",
    "        \"food\",\n",
    "    ],\n",
    "    min_topic_size=100,\n",
    "    language=\"brazilian portuguese\",\n",
    "    low_memory=True,\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clusters\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "6    77159\n",
       "5    41767\n",
       "7     6000\n",
       "8     2829\n",
       "0      249\n",
       "1      205\n",
       "2      186\n",
       "9      150\n",
       "3      133\n",
       "4       75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clusters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532182199601841"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
