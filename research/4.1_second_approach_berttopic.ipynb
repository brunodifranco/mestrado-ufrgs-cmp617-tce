{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_cleaning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCleaning\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src'"
     ]
    }
   ],
   "source": [
    "from typing import AnyStr\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"src\")\n",
    "from data_cleaning import DataCleaning\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 19:29:31.030024: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 19:29:31.030301: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 19:29:31.032237: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 19:29:31.058006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 19:29:31.758148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre as métricas de avaliação\n",
    "https://github.com/dice-group/Palmetto/issues/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"zero-shot-classification\",\n",
    "#     model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n",
    "#     framework=\"pt\",\n",
    "#     device=device,\n",
    "#     batch_size=16,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 19:29:34 - INFO - Data loaded!\n",
      "2024-04-11 19:29:34 - INFO - Null values cleaned!\n",
      "2024-04-11 19:29:34 - INFO - Data types asserted!\n",
      "2024-04-11 19:29:34 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "data_cleaning_pipeline = DataCleaning()\n",
    "df = data_cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df)\n",
    "docs = data[\"DS_OBJETO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "with open(\"/home/brunodifranco/mestrado/mestrado-ufrgs-cmp617-tce/src/utils/stop_words.txt\", \"r\") as file:\n",
    "    for row in file:\n",
    "        stop_words.append(row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words)\n",
    "# topic_model = BERTopic(vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=\"auto\",\n",
    "    embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=15,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54e36ef14964cbcba5c53b6b7fdd0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230ed66980174f9fa2294450876f2dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9044a3fe860c455b83669e613b926ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5aac58cf64a15820b56e25e801a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52dc95fa7c3467386ef08dd0fbbb0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a1864a3cb347228beb6b7af2f9a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2668730f581841a1a6f95d247605591b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b97f961f9ec42ad9c236bec1873276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4010b8f3a3ef4afa957d61194e15e574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddc652b4ae641dd9088b9a876427041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edef1cb28afc451a836d93aa247060ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunodifranco/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('educação', 0.53414416),\n",
       "  ('assistência', 0.44041756),\n",
       "  ('sinalização', 0.42389134),\n",
       "  ('agricultura', 0.42360923),\n",
       "  ('construção', 0.41972032),\n",
       "  ('escola', 0.419574),\n",
       "  ('execução', 0.4119953),\n",
       "  ('referência', 0.40376467),\n",
       "  ('locação', 0.39269838),\n",
       "  ('escolas', 0.39153555)],\n",
       " 1: [('família', 0.5922185),\n",
       "  ('medicamentos', 0.44498968),\n",
       "  ('medicao', 0.4081061),\n",
       "  ('projecao', 0.39517975),\n",
       "  ('geriátricas', 0.36872268),\n",
       "  ('geriatricas', 0.36872265),\n",
       "  ('hospitalares', 0.3532731),\n",
       "  ('panificacao', 0.33553988),\n",
       "  ('pacientes', 0.31375098),\n",
       "  ('medico', 0.3042565)],\n",
       " 2: [('combustíveis', 0.5134498),\n",
       "  ('combustiveis', 0.5134498),\n",
       "  ('combustivel', 0.5078111),\n",
       "  ('combustível', 0.50781107),\n",
       "  ('diesel', 0.4961721),\n",
       "  ('petróleo', 0.39581764),\n",
       "  ('gasolina', 0.3122659),\n",
       "  ('gás', 0.30902255),\n",
       "  ('óleo', 0.294863),\n",
       "  ('oléo', 0.29486293)],\n",
       " 3: [('implantação', 0.6170585),\n",
       "  ('implantes', 0.5991131),\n",
       "  ('implante', 0.5695007),\n",
       "  ('sinalização', 0.39835203),\n",
       "  ('pavimentação', 0.35648924),\n",
       "  ('identificação', 0.3490078),\n",
       "  ('acessibilidade', 0.34087896),\n",
       "  ('implementação', 0.32432765),\n",
       "  ('instalação', 0.31261414),\n",
       "  ('contratação', 0.3074353)],\n",
       " 4: [('covid', 0.53526294),\n",
       "  ('antígenos', 0.44890237),\n",
       "  ('coronavírus', 0.44784084),\n",
       "  ('coronavirus', 0.44784084),\n",
       "  ('antigeno', 0.44415128),\n",
       "  ('antígeno', 0.44415128),\n",
       "  ('diagnóstico', 0.34490305),\n",
       "  ('influenza', 0.32606512),\n",
       "  ('vacinação', 0.30925253),\n",
       "  ('testes', 0.3043247)],\n",
       " 5: [('sms', 0.69194007),\n",
       "  ('smsas', 0.5837177),\n",
       "  ('smsurb', 0.5161123),\n",
       "  ('smseg', 0.500882),\n",
       "  ('smsp', 0.4967658),\n",
       "  ('medicamentos', 0.43907613),\n",
       "  ('texto', 0.43446457),\n",
       "  ('médico', 0.37127167),\n",
       "  ('sinalização', 0.3564991),\n",
       "  ('odontológico', 0.35197026)],\n",
       " 6: [('bateriaspregao', 0.7817762),\n",
       "  ('baterias', 0.73654497),\n",
       "  ('bateriais', 0.72179383),\n",
       "  ('bateria', 0.7204664),\n",
       "  ('batas', 0.58772075),\n",
       "  ('reposição', 0.4974134),\n",
       "  ('definição', 0.48949993),\n",
       "  ('referência', 0.48073298),\n",
       "  ('estacionárias', 0.4698999),\n",
       "  ('processamento', 0.4671226)],\n",
       " 7: [('compressor', 0.674917),\n",
       "  ('compressores', 0.6590801),\n",
       "  ('pneumático', 0.4382853),\n",
       "  ('pneumaticospregao', 0.43811908),\n",
       "  ('pneumáticos', 0.42074007),\n",
       "  ('pneumatica', 0.413451),\n",
       "  ('pneumática', 0.413451),\n",
       "  ('conservação', 0.41126573),\n",
       "  ('pneumáticas', 0.40355134),\n",
       "  ('refrigerado', 0.37524062)],\n",
       " 8: [('transporte', 0.7552732),\n",
       "  ('escolar', 0.6996832),\n",
       "  ('escolarveículo', 0.65440065),\n",
       "  ('escolares', 0.6336187),\n",
       "  ('específicações', 0.43214786),\n",
       "  ('trasnporte', 0.40451723),\n",
       "  ('eletronico', 0.3378082),\n",
       "  ('eletrônico', 0.3378082),\n",
       "  ('volare', 0.31582785),\n",
       "  ('parcelado', 0.3154534)],\n",
       " 9: [('inservivei', 0.68366015),\n",
       "  ('inserviveis', 0.6375124),\n",
       "  ('inservíveis', 0.6375123),\n",
       "  ('leilao', 0.61872125),\n",
       "  ('leilão', 0.61872125),\n",
       "  ('insersiveis', 0.48291668),\n",
       "  ('balanceamento', 0.4174347),\n",
       "  ('contratação', 0.4070477),\n",
       "  ('funerarios', 0.39190704),\n",
       "  ('funerários', 0.39190704)],\n",
       " 10: [('gráfico', 0.7623037),\n",
       "  ('grafico', 0.7623037),\n",
       "  ('rp', 0.23458506),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325),\n",
       "  ('', 0.23445325)],\n",
       " 11: [('ram', 0.50829905),\n",
       "  ('mhz', 0.43589216),\n",
       "  ('intel', 0.3904122),\n",
       "  ('lga1200', 0.3901277),\n",
       "  ('512gb', 0.3875262),\n",
       "  ('ssd', 0.38058206),\n",
       "  ('notebook', 0.379476),\n",
       "  ('ghz', 0.37026262),\n",
       "  ('64bits', 0.36572343),\n",
       "  ('240gb', 0.35617512)],\n",
       " 12: [('medicamentos', 0.99921703),\n",
       "  ('medicamento', 0.9574319),\n",
       "  ('médicos', 0.5697665),\n",
       "  ('doces', 0.41140896),\n",
       "  ('complexidade', 0.28656548),\n",
       "  ('humanos', 0.19755098),\n",
       "  ('alta', 0.18217193),\n",
       "  ('', 0.17593092),\n",
       "  ('', 0.17593092),\n",
       "  ('', 0.17593092)],\n",
       " 13: [('massey', 0.5465158),\n",
       "  ('ferguson', 0.40919518),\n",
       "  ('tração', 0.3617673),\n",
       "  ('reposição', 0.35836688),\n",
       "  ('lotado', 0.34243602),\n",
       "  ('trator', 0.31987602),\n",
       "  ('placaizr1d69', 0.31829643),\n",
       "  ('fergusson', 0.30549875),\n",
       "  ('recuperação', 0.30261427),\n",
       "  ('carraro', 0.3018911)],\n",
       " 14: [('bacillusthuringiensis', 0.7695377),\n",
       "  ('thuringiensis', 0.6838893),\n",
       "  ('bacillus', 0.5767735),\n",
       "  ('bacilluss', 0.56163275),\n",
       "  ('bacilus', 0.37180597),\n",
       "  ('bti', 0.3691546),\n",
       "  ('israelensis', 0.36027804),\n",
       "  ('mosquito', 0.3197084),\n",
       "  ('indoxacarbe', 0.30639532),\n",
       "  ('biológico', 0.28511357)],\n",
       " 15: [('termômetro', 0.62672865),\n",
       "  ('termometro', 0.62672865),\n",
       "  ('termômetros', 0.60021234),\n",
       "  ('termometros', 0.60021234),\n",
       "  ('térmica', 0.52452374),\n",
       "  ('termostato', 0.5226265),\n",
       "  ('térmicas', 0.5035556),\n",
       "  ('termohigrometro', 0.48075747),\n",
       "  ('digital', 0.47319794),\n",
       "  ('digitais', 0.42928874)],\n",
       " 16: [('submersa', 0.42822087),\n",
       "  ('gmb', 0.3275448),\n",
       "  ('40mca', 0.31623608),\n",
       "  ('20m3', 0.29905713),\n",
       "  ('30m3', 0.2885251),\n",
       "  ('45m3', 0.2811677),\n",
       "  ('30mca', 0.27903968),\n",
       "  ('22mca', 0.26370236),\n",
       "  ('16m3', 0.26125255),\n",
       "  ('20mca', 0.24197735)],\n",
       " 17: [('trator', 0.41039822),\n",
       "  ('aquisição', 0.22715314),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251),\n",
       "  ('', 0.14065251)],\n",
       " 18: [('receptores', 0.497778),\n",
       "  ('receptor', 0.4929191),\n",
       "  ('gnss', 0.43816286),\n",
       "  ('rtk', 0.41949555),\n",
       "  ('gps', 0.25257617),\n",
       "  ('geodésico', 0.19607598),\n",
       "  ('levantamentos', 0.18972754),\n",
       "  ('rkt', 0.17692098),\n",
       "  ('levantamento', 0.16065526),\n",
       "  ('trenas', 0.15678504)]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_red = topic_model.reduce_topics(docs, nr_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: [('administração', 0.5128263),\n",
       "  ('construção', 0.48023286),\n",
       "  ('elaboração', 0.47881675),\n",
       "  ('sinalização', 0.47879952),\n",
       "  ('educação', 0.47509193),\n",
       "  ('pavimentação', 0.46780133),\n",
       "  ('contratação', 0.4645041),\n",
       "  ('realização', 0.46154442),\n",
       "  ('assistência', 0.43208027),\n",
       "  ('público', 0.42825383)],\n",
       " 0: [('educação', 0.49767995),\n",
       "  ('construção', 0.4613402),\n",
       "  ('assistência', 0.45131466),\n",
       "  ('referência', 0.42996985),\n",
       "  ('alimentícios', 0.4158863),\n",
       "  ('contratação', 0.4132297),\n",
       "  ('pavimentação', 0.41275293),\n",
       "  ('escola', 0.3991003),\n",
       "  ('transporte', 0.39902392),\n",
       "  ('administração', 0.38902014)],\n",
       " 1: [('gráfico', 0.76230395),\n",
       "  ('grafico', 0.76230395),\n",
       "  ('rp', 0.23458505),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533),\n",
       "  ('', 0.2344533)],\n",
       " 2: [('medicamentos', 0.99999994),\n",
       "  ('medicamento', 0.9603776),\n",
       "  ('médicos', 0.56999767),\n",
       "  ('doces', 0.40482494),\n",
       "  ('complexidade', 0.29081422),\n",
       "  ('humanos', 0.19442846),\n",
       "  ('alta', 0.18158409),\n",
       "  ('', 0.17246795),\n",
       "  ('', 0.17246795),\n",
       "  ('', 0.17246795)],\n",
       " 3: [('trator', 0.4084736),\n",
       "  ('aquisição', 0.2281385),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727),\n",
       "  ('', 0.14090727)]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_red.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topics_red._preprocess_text(docs)\n",
    "vectorizer = topics_red.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topics_red.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topics_red.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topics_red.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3720869663260227"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)][:10]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                          texts=tokens, \n",
    "                          corpus=corpus,\n",
    "                          dictionary=dictionary, \n",
    "                          coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4260404204330265"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nlp import preprocess, remove_stop_words, stemmer_pt, lemma_pt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.assign(\n",
    "#     DS_OBJETO_NLP=df[\"DS_OBJETO\"]\n",
    "#     .apply(\n",
    "#         lambda x: nltk.word_tokenize(x.lower(), language=\"portuguese\")\n",
    "#     )  # Tokenize\n",
    "#     .apply(lambda x: [preprocess(word) for word in x])  # Other preprocessing\n",
    "#     .apply(lambda x: list(filter(None, x)))  # Removes items with none\n",
    "#     .apply(remove_stop_words)  # Removes stop words\n",
    "#     .apply(\n",
    "#         lambda x: [word for word in x if \"rs\" not in word]\n",
    "#     )  # Remove tokens containing \"rs\" (which are cities)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(1000)\n",
    "\n",
    "data = Dataset.from_pandas(df)\n",
    "docs = data[\"DS_OBJETO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "# ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words)\n",
    "# topic_model = BERTopic(vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "#                        \"escola, alimenticio, educacao\", \n",
    "#                        \"limpeza, obra, predio\", \n",
    "#                        \"rua, construcao, pavimentacao\", \n",
    "#                        \"saude, medico, familia\",\n",
    "#                        \"servico, transporte, instalacao\",\n",
    "#                        \"veiculos, maquinas, frota\"]\n",
    "\n",
    "# # We fit our model using the zero-shot topics\n",
    "# # and we define a minimum similarity. For each document,\n",
    "# # if the similarity does not exceed that value, it will be used\n",
    "# # for clustering instead.\n",
    "# topic_model = BERTopic(\n",
    "#     embedding_model=\"all-MiniLM-L6-v2\", \n",
    "#     language=\"brazilian portuguese\",\n",
    "#     min_topic_size=15,\n",
    "#     zeroshot_topic_list=zeroshot_topic_list,\n",
    "#     zeroshot_min_similarity=.4,\n",
    "#     representation_model=KeyBERTInspired(),\n",
    "#     vectorizer_model=vectorizer_model\n",
    "\n",
    "# )\n",
    "# topics, _ = topic_model.fit_transform(docs[\"DS_OBJETO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_docs = topic_model._preprocess_text(docs[\"DS_OBJETO\"])\n",
    "# vectorizer = topic_model.vectorizer_model\n",
    "# analyzer = vectorizer.build_analyzer()\n",
    "# tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "# dictionary = corpora.Dictionary(tokens)\n",
    "# corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "# topics = topic_model.get_topics()\n",
    "# topics.pop(-1, None)\n",
    "# topic_words = [\n",
    "# [word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "# ]\n",
    "# topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "#         for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# # Evaluate\n",
    "# coherence_model = CoherenceModel(topics=topic_words, \n",
    "#                             texts=tokens, \n",
    "#                             corpus=corpus,\n",
    "#                             dictionary=dictionary, \n",
    "#                             coherence='c_v')\n",
    "# coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128753/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.5,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CoherenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50116</td>\n",
       "      <td>rua, construcao, pavimentacao</td>\n",
       "      <td>[construção, pavimentação, administração, real...</td>\n",
       "      <td>[Contratação de empresa para a execução de obr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32458</td>\n",
       "      <td>servico, transporte, instalacao</td>\n",
       "      <td>[contratação, serviços, administração, serviço...</td>\n",
       "      <td>[CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21647</td>\n",
       "      <td>saude, medico, familia</td>\n",
       "      <td>[medicamentos, médicos, medico, médico, atendi...</td>\n",
       "      <td>[Registro de Preço para a futura e eventual aq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12989</td>\n",
       "      <td>Escola, Educação</td>\n",
       "      <td>[alimentação, alimentacao, alimentícios, alime...</td>\n",
       "      <td>[Eventual e futura aquisição de gêneros alimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8996</td>\n",
       "      <td>veiculos, maquinas, frota</td>\n",
       "      <td>[pneus, veículos, veiculos, aquisição, proteto...</td>\n",
       "      <td>[AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1308</td>\n",
       "      <td>limpeza, obra, predio</td>\n",
       "      <td>[limpeza, limpa, limpador, aquisição, aquisiçõ...</td>\n",
       "      <td>[Aquisição de Material de Limpeza., Aquisição ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1239</td>\n",
       "      <td>eletrica, hidraulica</td>\n",
       "      <td>[hidráulicas, hidraulica, hidráulica, hidrauli...</td>\n",
       "      <td>[AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                             Name  \\\n",
       "0      0  50116    rua, construcao, pavimentacao   \n",
       "1      1  32458  servico, transporte, instalacao   \n",
       "2      2  21647           saude, medico, familia   \n",
       "3      3  12989                 Escola, Educação   \n",
       "4      4   8996        veiculos, maquinas, frota   \n",
       "5      5   1308            limpeza, obra, predio   \n",
       "6      6   1239             eletrica, hidraulica   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [construção, pavimentação, administração, real...   \n",
       "1  [contratação, serviços, administração, serviço...   \n",
       "2  [medicamentos, médicos, medico, médico, atendi...   \n",
       "3  [alimentação, alimentacao, alimentícios, alime...   \n",
       "4  [pneus, veículos, veiculos, aquisição, proteto...   \n",
       "5  [limpeza, limpa, limpador, aquisição, aquisiçõ...   \n",
       "6  [hidráulicas, hidraulica, hidráulica, hidrauli...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa para a execução de obr...  \n",
       "1  [CONTRATAÇÃO DE EMPRESA ESPECIALIZADA PARA PRE...  \n",
       "2  [Registro de Preço para a futura e eventual aq...  \n",
       "3  [Eventual e futura aquisição de gêneros alimen...  \n",
       "4  [AQUISIÇÃO DE PNEUS NOVOS PARA A FROTA DE VEÍC...  \n",
       "5  [Aquisição de Material de Limpeza., Aquisição ...  \n",
       "6  [AQUISIÇÃO DE UMA ESCAVADEIRA HIDRÁULICA, AQUI...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "zeroshot_topic_list = [\"eletrica, hidraulica\", \n",
    "                       \"Escola, Educação\", \n",
    "                       \"limpeza, obra, predio\", \n",
    "                       \"rua, construcao, pavimentacao\", \n",
    "                       \"saude, medico, familia\",\n",
    "                       \"servico, transporte, instalacao\",\n",
    "                       \"veiculos, maquinas, frota\"]\n",
    "\n",
    "min_topic_size = int(len(docs)/len(zeroshot_topic_list)*0.1) # Pelo menos 10% da divisao entre o total de observaçoes e o total de classes\n",
    "# We fit our model using the zero-shot topics\n",
    "# and we define a minimum similarity. For each document,\n",
    "# if the similarity does not exceed that value, it will be used\n",
    "# for clustering instead.\n",
    "topic_model = BERTopic(\n",
    "    # embedding_model=\"all-mpnet-base-v2\", \n",
    "    # embedding_model=\"all-MiniLM-L6-v2\", \n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    language=\"brazilian portuguese\",\n",
    "    min_topic_size=min_topic_size,\n",
    "    low_memory=True,\n",
    "    # zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.7,\n",
    "    representation_model=KeyBERTInspired(),\n",
    "    vectorizer_model=vectorizer_model\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4153744865189709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>construction</td>\n",
       "      <td>[empresas, empreitada, revitalização, paviment...</td>\n",
       "      <td>[Contratação de empresa, por regime de empreit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>health/hospital</td>\n",
       "      <td>[medicamentos, médico, referência, consultas, ...</td>\n",
       "      <td>[Constitui objeto da presente licitação o REGI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>education</td>\n",
       "      <td>[educação, educacao, escolares, escolas, escol...</td>\n",
       "      <td>[Contratação de prestação de serviços de Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>food</td>\n",
       "      <td>[alimentação, alimentacao, alimenticios, alime...</td>\n",
       "      <td>[AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>[referência, retroescavadeira, especificações,...</td>\n",
       "      <td>[Contratação de serviços de transporte com cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count             Name  \\\n",
       "0      0    332     construction   \n",
       "1      1    246  health/hospital   \n",
       "2      2    195        education   \n",
       "3      3    120             food   \n",
       "4      4    107         vehicles   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [empresas, empreitada, revitalização, paviment...   \n",
       "1  [medicamentos, médico, referência, consultas, ...   \n",
       "2  [educação, educacao, escolares, escolas, escol...   \n",
       "3  [alimentação, alimentacao, alimenticios, alime...   \n",
       "4  [referência, retroescavadeira, especificações,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Contratação de empresa, por regime de empreit...  \n",
       "1  [Constitui objeto da presente licitação o REGI...  \n",
       "2  [Contratação de prestação de serviços de Trans...  \n",
       "3  [AQUISIÇÃO DE GÊNEROS ALIMENTÍCIOS P/ALIMENTAÇ...  \n",
       "4  [Contratação de serviços de transporte com cam...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75280182/topic-modelling-coherence-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 00:27:15 - INFO - Data loaded!\n",
      "2024-04-05 00:27:15 - INFO - Null values cleaned!\n",
      "2024-04-05 00:27:15 - INFO - Data types asserted!\n",
      "2024-04-05 00:27:15 - INFO - Full data cleaned!\n"
     ]
    }
   ],
   "source": [
    "cleaning_pipeline = DataCleaning()\n",
    "df = cleaning_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"DS_OBJETO\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/mestrado-ufrgs/mestrado-ufrgs-cmp617-tce/.venv/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    nr_topics=5,\n",
    "    zeroshot_topic_list=[\n",
    "        \"vehicles\",\n",
    "        \"construction\",\n",
    "        \"health\",\n",
    "        \"education\",\n",
    "        \"food\",\n",
    "    ],\n",
    "    min_topic_size=100,\n",
    "    language=\"brazilian portuguese\",\n",
    "    low_memory=True,\n",
    ")\n",
    "topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clusters\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clusters\n",
       "6    77159\n",
       "5    41767\n",
       "7     6000\n",
       "8     2829\n",
       "0      249\n",
       "1      205\n",
       "2      186\n",
       "9      150\n",
       "3      133\n",
       "4       75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clusters\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "tokens = [analyzer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topics = topic_model.get_topics()\n",
    "topics.pop(-1, None)\n",
    "topic_words = [\n",
    "[word for word, _ in topic_model.get_topic(topic) if word != \"\"] for topic in topics\n",
    "]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "        for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                            texts=tokens, \n",
    "                            corpus=corpus,\n",
    "                            dictionary=dictionary, \n",
    "                            coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532182199601841"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
